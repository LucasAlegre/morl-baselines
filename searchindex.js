Search.setIndex({"alltitles": {"Accrued Reward Replay Buffer": [[16, "accrued-reward-replay-buffer"]], "Acknowledgements": [[15, "acknowledgements"]], "Algorithms": [[11, "algorithms"]], "Applicability and limitations": [[10, "applicability-and-limitations"]], "Benchmarking script": [[11, "benchmarking-script"]], "Benchmarks": [[25, "benchmarks"]], "Citing MORL-Baselines": [[25, "citing-morl-baselines"]], "Community": [[15, null]], "Concave-Augmented Pareto Q-Learning (CAPQL)": [[2, null]], "Contributing": [[15, "contributing"]], "Diverse Replay Buffer": [[16, "diverse-replay-buffer"]], "EUPG": [[13, null]], "Envelope Q-Learning": [[3, null]], "Evaluations": [[17, null]], "Features of MORL-Baselines": [[25, "features-of-morl-baselines"]], "GPI-Prioritized Dyna": [[4, null]], "Hyperparameter optimization": [[18, null]], "Introduction": [[11, "introduction"]], "Linear Support": [[5, null]], "MOPPO": [[10, "moppo"]], "MOQ-Learning": [[14, null]], "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.": [[25, null]], "MORL/D": [[6, null]], "MPMOQ Learning": [[7, null]], "Maintainers": [[15, "maintainers"]], "Metrics": [[11, "metrics"]], "Miscellaneous": [[19, null]], "Multi-Objective Replay Buffer": [[16, "multi-objective-replay-buffer"]], "Multi-Policy Algorithms": [[1, null]], "Multi-policy algorithms": [[11, "multi-policy-algorithms"]], "Neural Networks helpers": [[20, null]], "Overview": [[0, null], [26, null]], "PGMORL": [[10, null], [10, "id1"]], "Pareto Conditioned Networks": [[9, null]], "Pareto Q-Learning": [[8, null]], "Pareto utils": [[21, null]], "Performance assessments": [[11, null]], "Performance indicators": [[22, null]], "Principle": [[10, "principle"]], "Prioritized Replay Buffer": [[16, "prioritized-replay-buffer"]], "References": [[11, "references"]], "Replay Buffers": [[16, null]], "Scalarization functions": [[23, null]], "Single-policy Algorithms": [[12, null]], "Single-policy algorithms": [[11, "single-policy-algorithms"]], "Storage": [[11, "storage"]], "Weight generator - prediction model": [[10, "weight-generator-prediction-model"]], "Weights helpers": [[24, null]]}, "docnames": ["algos/algorithms", "algos/multi_policy", "algos/multi_policy/capql", "algos/multi_policy/envelope", "algos/multi_policy/gpi_pd", "algos/multi_policy/linear_support", "algos/multi_policy/morld", "algos/multi_policy/mp_mo_q_learning", "algos/multi_policy/pareto_q_learning", "algos/multi_policy/pcn", "algos/multi_policy/pgmorl", "algos/performances", "algos/single_policy", "algos/single_policy/eupg", "algos/single_policy/moq_learning", "community/community", "features/buffers", "features/evaluations", "features/hpo", "features/misc", "features/networks", "features/pareto", "features/performance_indicators", "features/scalarization", "features/weights", "index", "quickstart/overview"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2}, "filenames": ["algos/algorithms.md", "algos/multi_policy.md", "algos/multi_policy/capql.md", "algos/multi_policy/envelope.md", "algos/multi_policy/gpi_pd.md", "algos/multi_policy/linear_support.md", "algos/multi_policy/morld.md", "algos/multi_policy/mp_mo_q_learning.md", "algos/multi_policy/pareto_q_learning.md", "algos/multi_policy/pcn.md", "algos/multi_policy/pgmorl.md", "algos/performances.md", "algos/single_policy.md", "algos/single_policy/eupg.md", "algos/single_policy/moq_learning.md", "community/community.md", "features/buffers.md", "features/evaluations.md", "features/hpo.md", "features/misc.md", "features/networks.md", "features/pareto.md", "features/performance_indicators.md", "features/scalarization.md", "features/weights.md", "index.md", "quickstart/overview.md"], "indexentries": {"accruedrewardreplaybuffer (class in morl_baselines.common.accrued_reward_buffer)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer", false]], "act() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.act", false]], "add() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.add", false]], "add() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.add", false]], "add() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.add", false]], "add() (morl_baselines.common.pareto.paretoarchive method)": [[21, "morl_baselines.common.pareto.ParetoArchive.add", false]], "add() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.add", false]], "add() (morl_baselines.multi_policy.pgmorl.pgmorl.performancepredictor method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor.add", false]], "add_sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.add_sample", false]], "add_solution() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.add_solution", false]], "add_tree() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.add_tree", false]], "calc_non_dominated() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.calc_non_dominated", false]], "capql (class in morl_baselines.multi_policy.capql.capql)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL", false]], "cardinality() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.cardinality", false]], "change_weights() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.change_weights", false]], "cleanup() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.cleanup", false]], "compute_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.compute_corner_weights", false]], "ddqn_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.ddqn_target", false]], "delete_policies() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.delete_policies", false]], "diversememory (class in morl_baselines.common.diverse_buffer)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory", false]], "dupe() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.dupe", false]], "ended() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ended", false]], "envelope (class in morl_baselines.multi_policy.envelope.envelope)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope", false]], "envelope_target() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.envelope_target", false]], "equally_spaced_weights() (in module morl_baselines.common.weights)": [[24, "morl_baselines.common.weights.equally_spaced_weights", false]], "eupg (class in morl_baselines.single_policy.esr.eupg)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG", false]], "eval() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.eval", false]], "eval() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.eval", false]], "eval() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.eval", false]], "eval() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.eval", false]], "eval() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.eval", false]], "eval() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.eval", false]], "eval() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.eval", false]], "eval() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.eval", false]], "eval_mo() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.eval_mo", false]], "eval_mo_reward_conditioned() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.eval_mo_reward_conditioned", false]], "evaluate() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.evaluate", false]], "expected_utility() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.expected_utility", false]], "extract_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.extract_trace", false]], "extrema_weights() (in module morl_baselines.common.weights)": [[24, "morl_baselines.common.weights.extrema_weights", false]], "filter_convex_dominated() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.filter_convex_dominated", false]], "filter_pareto_dominated() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.filter_pareto_dominated", false]], "forward() (morl_baselines.common.networks.naturecnn method)": [[20, "morl_baselines.common.networks.NatureCNN.forward", false]], "get() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get", false]], "get_all_data() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.get_all_data", false]], "get_all_data() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.get_all_data", false]], "get_all_data() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.get_all_data", false]], "get_buffer() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.get_buffer", false]], "get_config() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.get_config", false]], "get_config() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.get_config", false]], "get_config() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.get_config", false]], "get_config() (morl_baselines.multi_policy.morld.morld.morld method)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD.get_config", false]], "get_config() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.get_config", false]], "get_config() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_config", false]], "get_config() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.get_config", false]], "get_config() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.get_config", false]], "get_config() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.get_config", false]], "get_config() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.get_config", false]], "get_corner_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_corner_weights", false]], "get_data() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_data", false]], "get_error() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_error", false]], "get_grad_norm() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.get_grad_norm", false]], "get_local_pcs() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_local_pcs", false]], "get_non_dominated() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.get_non_dominated", false]], "get_non_dominated_inds() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.get_non_dominated_inds", false]], "get_non_pareto_dominated_inds() (in module morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.get_non_pareto_dominated_inds", false]], "get_policy_net() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.get_policy_net", false]], "get_q_set() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.get_q_set", false]], "get_save_dict() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.get_save_dict", false]], "get_sec_write() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_sec_write", false]], "get_trace_value() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.get_trace_value", false]], "get_weight_support() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.get_weight_support", false]], "gpi_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.gpi_action", false]], "gpi_ls_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.gpi_ls_priority", false]], "gpipd (class in morl_baselines.multi_policy.gpi_pd.gpi_pd)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD", false]], "huber() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.huber", false]], "hypervolume() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.hypervolume", false]], "igd() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.igd", false]], "is_dominated() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.is_dominated", false]], "layer_init() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.layer_init", false]], "linearly_decaying_value() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.linearly_decaying_value", false]], "linearsupport (class in morl_baselines.multi_policy.linear_support.linear_support)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport", false]], "load() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.load", false]], "load() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.load", false]], "load() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.load", false]], "load() (morl_baselines.multi_policy.morld.morld.morld method)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD.load", false]], "load() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.load", false]], "load() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.load", false]], "log_all_multi_policy_metrics() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.log_all_multi_policy_metrics", false]], "log_episode_info() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.log_episode_info", false]], "main_mem_is_full() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.main_mem_is_full", false]], "make_gif() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.make_gif", false]], "max_action() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.max_action", false]], "max_action() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.max_action", false]], "max_scalar_q_value() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.max_scalar_q_value", false]], "max_scalarized_value() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_scalarized_value", false]], "max_value_lp() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.max_value_lp", false]], "maximum_utility_loss() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.maximum_utility_loss", false]], "mlp() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.mlp", false]], "module": [[17, "module-morl_baselines.common.evaluation", false], [19, "module-morl_baselines.common.utils", false], [20, "module-morl_baselines.common.networks", false], [21, "module-morl_baselines.common.pareto", false], [22, "module-morl_baselines.common.performance_indicators", false], [23, "module-morl_baselines.common.scalarization", false], [24, "module-morl_baselines.common.weights", false]], "moppo (class in morl_baselines.single_policy.ser.mo_ppo)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO", false]], "moqlearning (class in morl_baselines.single_policy.ser.mo_q_learning)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning", false]], "morl_baselines.common.evaluation": [[17, "module-morl_baselines.common.evaluation", false]], "morl_baselines.common.networks": [[20, "module-morl_baselines.common.networks", false]], "morl_baselines.common.pareto": [[21, "module-morl_baselines.common.pareto", false]], "morl_baselines.common.performance_indicators": [[22, "module-morl_baselines.common.performance_indicators", false]], "morl_baselines.common.scalarization": [[23, "module-morl_baselines.common.scalarization", false]], "morl_baselines.common.utils": [[19, "module-morl_baselines.common.utils", false]], "morl_baselines.common.weights": [[24, "module-morl_baselines.common.weights", false]], "morld (class in morl_baselines.multi_policy.morld.morld)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD", false]], "move_to_sec() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.move_to_sec", false]], "mpmoqlearning (class in morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning", false]], "naturecnn (class in morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.NatureCNN", false]], "nearest_neighbors() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.nearest_neighbors", false]], "next_weight() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.next_weight", false]], "ols_priority() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.ols_priority", false]], "paretoarchive (class in morl_baselines.common.pareto)": [[21, "morl_baselines.common.pareto.ParetoArchive", false]], "pcn (class in morl_baselines.multi_policy.pcn.pcn)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN", false]], "performancepredictor (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor", false]], "pgmorl (class in morl_baselines.multi_policy.pgmorl.pgmorl)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL", false]], "policy_evaluation_mo() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.policy_evaluation_mo", false]], "polyak_update() (in module morl_baselines.common.networks)": [[20, "morl_baselines.common.networks.polyak_update", false]], "pql (class in morl_baselines.multi_policy.pareto_q_learning.pql)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL", false]], "predict_next_evaluation() (morl_baselines.multi_policy.pgmorl.pgmorl.performancepredictor method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor.predict_next_evaluation", false]], "prioritizedreplaybuffer (class in morl_baselines.common.prioritized_buffer)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer", false]], "random_weights() (in module morl_baselines.common.weights)": [[24, "morl_baselines.common.weights.random_weights", false]], "remove_obsolete_values() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_values", false]], "remove_obsolete_weights() (morl_baselines.multi_policy.linear_support.linear_support.linearsupport method)": [[5, "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport.remove_obsolete_weights", false]], "remove_trace() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.remove_trace", false]], "replaybuffer (class in morl_baselines.common.buffer)": [[16, "morl_baselines.common.buffer.ReplayBuffer", false]], "reset_wandb_env() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.reset_wandb_env", false]], "sample() (morl_baselines.common.accrued_reward_buffer.accruedrewardreplaybuffer method)": [[16, "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer.sample", false]], "sample() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.sample", false]], "sample() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.sample", false]], "sample() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample", false]], "sample_obs() (morl_baselines.common.buffer.replaybuffer method)": [[16, "morl_baselines.common.buffer.ReplayBuffer.sample_obs", false]], "sample_obs() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.sample_obs", false]], "save() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.save", false]], "save() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.save", false]], "save() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.save", false]], "save() (morl_baselines.multi_policy.morld.morld.morld method)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD.save", false]], "save() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.save", false]], "scalarized_q_values() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.scalarized_q_values", false]], "score_hypervolume() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_hypervolume", false]], "score_pareto_cardinality() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.score_pareto_cardinality", false]], "sec_distances() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.sec_distances", false]], "seed_everything() (in module morl_baselines.common.evaluation)": [[17, "morl_baselines.common.evaluation.seed_everything", false]], "select_action() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.select_action", false]], "set_buffer() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.set_buffer", false]], "set_desired_return_and_horizon() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.set_desired_return_and_horizon", false]], "set_weight_support() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.set_weight_support", false]], "set_weights() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.set_weights", false]], "sparsity() (in module morl_baselines.common.performance_indicators)": [[22, "morl_baselines.common.performance_indicators.sparsity", false]], "tchebicheff() (in module morl_baselines.common.scalarization)": [[23, "morl_baselines.common.scalarization.tchebicheff", false]], "track_policy() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.track_policy", false]], "train() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.train", false]], "train() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.train", false]], "train() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train", false]], "train() (morl_baselines.multi_policy.morld.morld.morld method)": [[6, "morl_baselines.multi_policy.morld.morld.MORLD.train", false]], "train() (morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.mpmoqlearning method)": [[7, "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning.train", false]], "train() (morl_baselines.multi_policy.pareto_q_learning.pql.pql method)": [[8, "morl_baselines.multi_policy.pareto_q_learning.pql.PQL.train", false]], "train() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.train", false]], "train() (morl_baselines.multi_policy.pgmorl.pgmorl.pgmorl method)": [[10, "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL.train", false]], "train() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.train", false]], "train() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.train", false]], "train() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.train", false]], "train_iteration() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.train_iteration", false]], "unique_tol() (in module morl_baselines.common.utils)": [[19, "morl_baselines.common.utils.unique_tol", false]], "update() (morl_baselines.common.diverse_buffer.diversememory method)": [[16, "morl_baselines.common.diverse_buffer.DiverseMemory.update", false]], "update() (morl_baselines.multi_policy.capql.capql.capql method)": [[2, "morl_baselines.multi_policy.capql.capql.CAPQL.update", false]], "update() (morl_baselines.multi_policy.envelope.envelope.envelope method)": [[3, "morl_baselines.multi_policy.envelope.envelope.Envelope.update", false]], "update() (morl_baselines.multi_policy.gpi_pd.gpi_pd.gpipd method)": [[4, "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD.update", false]], "update() (morl_baselines.multi_policy.pcn.pcn.pcn method)": [[9, "morl_baselines.multi_policy.pcn.pcn.PCN.update", false]], "update() (morl_baselines.single_policy.esr.eupg.eupg method)": [[13, "morl_baselines.single_policy.esr.eupg.EUPG.update", false]], "update() (morl_baselines.single_policy.ser.mo_ppo.moppo method)": [[10, "morl_baselines.single_policy.ser.mo_ppo.MOPPO.update", false]], "update() (morl_baselines.single_policy.ser.mo_q_learning.moqlearning method)": [[14, "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning.update", false]], "update_priorities() (morl_baselines.common.prioritized_buffer.prioritizedreplaybuffer method)": [[16, "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer.update_priorities", false]], "weighted_sum() (in module morl_baselines.common.scalarization)": [[23, "morl_baselines.common.scalarization.weighted_sum", false]]}, "objects": {"morl_baselines.common": [[17, 2, 0, "-", "evaluation"], [20, 2, 0, "-", "networks"], [21, 2, 0, "-", "pareto"], [22, 2, 0, "-", "performance_indicators"], [23, 2, 0, "-", "scalarization"], [19, 2, 0, "-", "utils"], [24, 2, 0, "-", "weights"]], "morl_baselines.common.accrued_reward_buffer": [[16, 0, 1, "", "AccruedRewardReplayBuffer"]], "morl_baselines.common.accrued_reward_buffer.AccruedRewardReplayBuffer": [[16, 1, 1, "", "add"], [16, 1, 1, "", "cleanup"], [16, 1, 1, "", "get_all_data"], [16, 1, 1, "", "sample"]], "morl_baselines.common.buffer": [[16, 0, 1, "", "ReplayBuffer"]], "morl_baselines.common.buffer.ReplayBuffer": [[16, 1, 1, "", "add"], [16, 1, 1, "", "get_all_data"], [16, 1, 1, "", "sample"], [16, 1, 1, "", "sample_obs"]], "morl_baselines.common.diverse_buffer": [[16, 0, 1, "", "DiverseMemory"]], "morl_baselines.common.diverse_buffer.DiverseMemory": [[16, 1, 1, "", "add"], [16, 1, 1, "", "add_sample"], [16, 1, 1, "", "add_tree"], [16, 1, 1, "", "dupe"], [16, 1, 1, "", "extract_trace"], [16, 1, 1, "", "get"], [16, 1, 1, "", "get_data"], [16, 1, 1, "", "get_error"], [16, 1, 1, "", "get_sec_write"], [16, 1, 1, "", "get_trace_value"], [16, 1, 1, "", "main_mem_is_full"], [16, 1, 1, "", "move_to_sec"], [16, 1, 1, "", "remove_trace"], [16, 1, 1, "", "sample"], [16, 1, 1, "", "sec_distances"], [16, 1, 1, "", "update"]], "morl_baselines.common.evaluation": [[17, 3, 1, "", "eval_mo"], [17, 3, 1, "", "eval_mo_reward_conditioned"], [17, 3, 1, "", "log_all_multi_policy_metrics"], [17, 3, 1, "", "log_episode_info"], [17, 3, 1, "", "policy_evaluation_mo"], [17, 3, 1, "", "seed_everything"]], "morl_baselines.common.networks": [[20, 0, 1, "", "NatureCNN"], [20, 3, 1, "", "get_grad_norm"], [20, 3, 1, "", "huber"], [20, 3, 1, "", "layer_init"], [20, 3, 1, "", "mlp"], [20, 3, 1, "", "polyak_update"]], "morl_baselines.common.networks.NatureCNN": [[20, 1, 1, "", "forward"]], "morl_baselines.common.pareto": [[21, 0, 1, "", "ParetoArchive"], [21, 3, 1, "", "filter_convex_dominated"], [21, 3, 1, "", "filter_pareto_dominated"], [21, 3, 1, "", "get_non_dominated"], [21, 3, 1, "", "get_non_dominated_inds"], [21, 3, 1, "", "get_non_pareto_dominated_inds"]], "morl_baselines.common.pareto.ParetoArchive": [[21, 1, 1, "", "add"]], "morl_baselines.common.performance_indicators": [[22, 3, 1, "", "cardinality"], [22, 3, 1, "", "expected_utility"], [22, 3, 1, "", "hypervolume"], [22, 3, 1, "", "igd"], [22, 3, 1, "", "maximum_utility_loss"], [22, 3, 1, "", "sparsity"]], "morl_baselines.common.prioritized_buffer": [[16, 0, 1, "", "PrioritizedReplayBuffer"]], "morl_baselines.common.prioritized_buffer.PrioritizedReplayBuffer": [[16, 1, 1, "", "add"], [16, 1, 1, "", "get_all_data"], [16, 1, 1, "", "sample"], [16, 1, 1, "", "sample_obs"], [16, 1, 1, "", "update_priorities"]], "morl_baselines.common.scalarization": [[23, 3, 1, "", "tchebicheff"], [23, 3, 1, "", "weighted_sum"]], "morl_baselines.common.utils": [[19, 3, 1, "", "linearly_decaying_value"], [19, 3, 1, "", "make_gif"], [19, 3, 1, "", "nearest_neighbors"], [19, 3, 1, "", "reset_wandb_env"], [19, 3, 1, "", "unique_tol"]], "morl_baselines.common.weights": [[24, 3, 1, "", "equally_spaced_weights"], [24, 3, 1, "", "extrema_weights"], [24, 3, 1, "", "random_weights"]], "morl_baselines.multi_policy.capql.capql": [[2, 0, 1, "", "CAPQL"]], "morl_baselines.multi_policy.capql.capql.CAPQL": [[2, 1, 1, "", "eval"], [2, 1, 1, "", "get_config"], [2, 1, 1, "", "load"], [2, 1, 1, "", "save"], [2, 1, 1, "", "train"], [2, 1, 1, "", "update"]], "morl_baselines.multi_policy.envelope.envelope": [[3, 0, 1, "", "Envelope"]], "morl_baselines.multi_policy.envelope.envelope.Envelope": [[3, 1, 1, "", "act"], [3, 1, 1, "", "ddqn_target"], [3, 1, 1, "", "envelope_target"], [3, 1, 1, "", "eval"], [3, 1, 1, "", "get_config"], [3, 1, 1, "", "load"], [3, 1, 1, "", "max_action"], [3, 1, 1, "", "save"], [3, 1, 1, "", "train"], [3, 1, 1, "", "update"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd": [[4, 0, 1, "", "GPIPD"]], "morl_baselines.multi_policy.gpi_pd.gpi_pd.GPIPD": [[4, 1, 1, "", "eval"], [4, 1, 1, "", "get_config"], [4, 1, 1, "", "gpi_action"], [4, 1, 1, "", "load"], [4, 1, 1, "", "max_action"], [4, 1, 1, "", "save"], [4, 1, 1, "", "set_weight_support"], [4, 1, 1, "", "train"], [4, 1, 1, "", "train_iteration"], [4, 1, 1, "", "update"]], "morl_baselines.multi_policy.linear_support.linear_support": [[5, 0, 1, "", "LinearSupport"]], "morl_baselines.multi_policy.linear_support.linear_support.LinearSupport": [[5, 1, 1, "", "add_solution"], [5, 1, 1, "", "compute_corner_weights"], [5, 1, 1, "", "ended"], [5, 1, 1, "", "get_corner_weights"], [5, 1, 1, "", "get_weight_support"], [5, 1, 1, "", "gpi_ls_priority"], [5, 1, 1, "", "is_dominated"], [5, 1, 1, "", "max_scalarized_value"], [5, 1, 1, "", "max_value_lp"], [5, 1, 1, "", "next_weight"], [5, 1, 1, "", "ols_priority"], [5, 1, 1, "", "remove_obsolete_values"], [5, 1, 1, "", "remove_obsolete_weights"]], "morl_baselines.multi_policy.morld.morld": [[6, 0, 1, "", "MORLD"]], "morl_baselines.multi_policy.morld.morld.MORLD": [[6, 1, 1, "", "get_config"], [6, 1, 1, "", "load"], [6, 1, 1, "", "save"], [6, 1, 1, "", "train"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning": [[7, 0, 1, "", "MPMOQLearning"]], "morl_baselines.multi_policy.multi_policy_moqlearning.mp_mo_q_learning.MPMOQLearning": [[7, 1, 1, "", "delete_policies"], [7, 1, 1, "", "eval"], [7, 1, 1, "", "get_config"], [7, 1, 1, "", "max_scalar_q_value"], [7, 1, 1, "", "train"]], "morl_baselines.multi_policy.pareto_q_learning.pql": [[8, 0, 1, "", "PQL"]], "morl_baselines.multi_policy.pareto_q_learning.pql.PQL": [[8, 1, 1, "", "calc_non_dominated"], [8, 1, 1, "", "get_config"], [8, 1, 1, "", "get_local_pcs"], [8, 1, 1, "", "get_q_set"], [8, 1, 1, "", "score_hypervolume"], [8, 1, 1, "", "score_pareto_cardinality"], [8, 1, 1, "", "select_action"], [8, 1, 1, "", "track_policy"], [8, 1, 1, "", "train"]], "morl_baselines.multi_policy.pcn.pcn": [[9, 0, 1, "", "PCN"]], "morl_baselines.multi_policy.pcn.pcn.PCN": [[9, 1, 1, "", "eval"], [9, 1, 1, "", "evaluate"], [9, 1, 1, "", "get_config"], [9, 1, 1, "", "load"], [9, 1, 1, "", "save"], [9, 1, 1, "", "set_desired_return_and_horizon"], [9, 1, 1, "", "train"], [9, 1, 1, "", "update"]], "morl_baselines.multi_policy.pgmorl.pgmorl": [[10, 0, 1, "", "PGMORL"], [10, 0, 1, "", "PerformancePredictor"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PGMORL": [[10, 1, 1, "", "get_config"], [10, 1, 1, "", "train"]], "morl_baselines.multi_policy.pgmorl.pgmorl.PerformancePredictor": [[10, 1, 1, "", "add"], [10, 1, 1, "", "predict_next_evaluation"]], "morl_baselines.single_policy.esr.eupg": [[13, 0, 1, "", "EUPG"]], "morl_baselines.single_policy.esr.eupg.EUPG": [[13, 1, 1, "", "eval"], [13, 1, 1, "", "get_buffer"], [13, 1, 1, "", "get_config"], [13, 1, 1, "", "get_policy_net"], [13, 1, 1, "", "get_save_dict"], [13, 1, 1, "", "load"], [13, 1, 1, "", "set_buffer"], [13, 1, 1, "", "set_weights"], [13, 1, 1, "", "train"], [13, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_ppo": [[10, 0, 1, "", "MOPPO"]], "morl_baselines.single_policy.ser.mo_ppo.MOPPO": [[10, 1, 1, "", "change_weights"], [10, 1, 1, "", "eval"], [10, 1, 1, "", "train"], [10, 1, 1, "", "update"]], "morl_baselines.single_policy.ser.mo_q_learning": [[14, 0, 1, "", "MOQLearning"]], "morl_baselines.single_policy.ser.mo_q_learning.MOQLearning": [[14, 1, 1, "", "eval"], [14, 1, 1, "", "get_config"], [14, 1, 1, "", "scalarized_q_values"], [14, 1, 1, "", "train"], [14, 1, 1, "", "update"]]}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "module", "Python module"], "3": ["py", "function", "Python function"]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:module", "3": "py:function"}, "terms": {"": [2, 3, 6, 10, 11, 13, 16, 17, 24, 26], "0": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 18, 19, 20, 24], "0001": [14, 19], "0003": [2, 3, 4, 10], "001": [8, 9, 13], "005": 2, "01": [3, 4, 16, 20], "022": 11, "03": 10, "05": 16, "06": 3, "07784": [4, 5], "08342": 3, "09552": 11, "1": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 19, 20, 24], "10": [6, 7, 9, 10, 11, 14, 18], "100": [2, 3, 4, 7, 9, 10, 18], "1000": [2, 4, 7, 8, 13, 14], "10000": [2, 3, 4, 6, 8, 18], "100000": [4, 8, 13, 16], "1000000": [2, 3, 4], "1007": 11, "10607": [10, 11], "10616": [10, 11], "11": 18, "1109": [7, 14], "1110": 9, "1118": 9, "12": 18, "128": [2, 4], "15": 8, "16487": 18, "19": 5, "1908": 3, "1e": [8, 9, 16], "1e6": 2, "2": [2, 4, 10, 11, 16], "20": [4, 9, 10], "200": [3, 18], "200000": 7, "2013": [7, 14], "2014": 8, "2015": [11, 19, 20, 22], "2018": 13, "2019": 3, "2020": [10, 11], "2021": 3, "2022": [9, 11], "2023": [2, 4, 18, 25], "2048": 10, "21st": 9, "2301": [4, 5], "2310": 18, "25": 18, "250": 4, "25000": 4, "256": [2, 3, 4, 9], "3": [0, 5, 8, 9, 10, 11, 18, 25], "300": 19, "32": [9, 10], "32791911": 21, "3483": 8, "3512": 8, "36": 11, "37th": [10, 11, 25], "3e": 2, "4": [2, 3, 10], "40000": 6, "42": [6, 10, 24], "43": 25, "48550": 18, "5": [2, 3, 4, 6, 7, 10, 14, 17], "50": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 19], "500": 10, "5000": 4, "500000": 14, "512": 20, "518": 20, "529": 20, "533": 20, "6": [3, 4, 6, 10, 14], "64": [9, 10], "6615007": [7, 14], "7": 10, "7540": 20, "8": 8, "80": 10, "9": [7, 14], "95": 10, "99": [2, 3, 4, 13], "995": [6, 10], "A": [3, 7, 8, 9, 10, 11, 13, 14, 16, 18, 19, 21, 22], "AND": 2, "As": 26, "At": 10, "But": 22, "For": [6, 11, 18, 25], "If": [3, 5, 7, 8, 14, 15, 16, 17, 25], "In": [9, 11], "It": [2, 11, 17, 18, 20, 23, 24, 25], "That": [11, 24], "The": [0, 2, 3, 4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 18, 19, 20, 21, 25, 26], "Then": 10, "There": 6, "These": [11, 16], "To": 11, "_gener": [6, 14], "_nestedsequ": 22, "_supportsarrai": 22, "a_bound_max": 10, "a_bound_min": 10, "aama": 4, "aamas2022": 9, "ab": [3, 4, 5], "abl": 11, "access": 3, "accord": 19, "accordingli": 11, "accru": [13, 17], "accrued_reward": [13, 16], "accrued_reward_buff": 16, "accruedrewardreplaybuff": 16, "act": 3, "action": [0, 2, 3, 4, 7, 8, 9, 10, 13, 14, 16], "action_dim": 16, "action_dtyp": 16, "action_ev": 8, "action_shap": 16, "activ": 20, "activation_fn": 20, "actor": [2, 10], "ad": [5, 16], "adapt": [3, 6, 10, 23], "add": [5, 9, 10, 16, 21], "add_sampl": 16, "add_solut": 5, "add_tre": 16, "adprl": [7, 14], "advantag": 10, "after": [5, 6, 10, 20], "agent": [2, 3, 4, 5, 6, 9, 10, 11, 13, 14, 17, 19], "ai": 25, "aim": 25, "al": [11, 19, 20], "alegr": [4, 15, 25], "algo": [5, 18], "algorithm": [0, 2, 3, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 18, 21, 22, 26], "all": [6, 7, 9, 11, 13, 15, 16, 17, 19, 21, 25, 26], "all_weight": 19, "allow": 11, "along": [10, 11], "alpha": [2, 3, 4, 10, 13, 14, 24], "alpha_p": 4, "also": [11, 15, 17, 25], "alwai": [15, 23], "an": [2, 3, 4, 5, 8, 10, 11, 15, 17, 18, 19, 20, 25], "ana": [4, 25], "analysi": [10, 11], "ani": [5, 22], "ann": [4, 25], "anneal": 10, "anneal_lr": 10, "answer": 21, "api": [11, 25], "appli": [3, 6, 10, 16], "approach": [11, 22], "approxim": [17, 22], "apr": 11, "ar": [0, 5, 6, 10, 11, 15, 16, 18, 21, 22, 24, 25], "architectur": [2, 4, 20], "archiv": [6, 21], "argument": 6, "arrai": [3, 7, 10, 13, 14, 16, 19, 21, 25], "array_lik": 8, "arxiv": [3, 4, 5, 18], "asid": 15, "ask": 15, "assess": 22, "assign": 10, "assum": 0, "assumpt": [11, 17], "author": [9, 10, 25], "auto": [2, 3, 4, 6, 9, 10, 13], "autom": 11, "automat": [17, 23, 25], "autonom": [9, 11], "avail": [3, 9, 10, 11, 16, 18, 25], "averag": [11, 17, 20, 22], "avg": 17, "axelabel": 16, "axiomat": 22, "bargiacchi": 9, "base": [2, 6, 8, 10, 11, 13, 22, 25], "baselin": [0, 2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 15, 18, 19, 26], "basepcnmodel": 9, "basic": 22, "batch": [2, 3, 4, 9, 16, 21], "batch_siz": [2, 3, 4, 9, 16], "bazzan": [4, 25], "beau": [11, 22], "becaus": 16, "been": [10, 19, 21, 25], "befor": [2, 3, 4, 10, 14, 19], "begin": [17, 19], "being": 5, "below": [11, 16], "benchmark": 18, "best": [3, 7, 10, 13, 14, 23], "better": 5, "between": [2, 4, 6, 11, 14, 22], "bia": 20, "bias": 25, "bias_const": 20, "blob": 10, "booktitl": 25, "bool": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 20, 21, 22], "boolean": 21, "both": [5, 6, 11, 25], "bound": 5, "bruno": [4, 25], "buffer": [2, 3, 4, 6, 9, 10, 13, 25, 26], "buffer_s": [2, 3, 4, 13], "bug": 15, "byte": 22, "c": [3, 4, 11, 25], "calc_non_domin": 8, "calcul": [2, 4, 7, 9, 21], "call": [5, 17], "callabl": [4, 6, 8, 13, 19, 22, 23], "can": [6, 11, 13, 15, 19, 25], "candid": [10, 21], "capac": 16, "capql": 0, "cardin": [8, 11, 22], "care": 17, "case": [9, 14], "castro": 25, "cc": [5, 11], "cer": 16, "chang": [3, 4, 10, 11, 21], "change_w_every_episod": 4, "change_weight": 10, "check": [5, 16], "checkpoint": [2, 4, 6], "choos": [7, 14], "circular": 16, "class": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 20, 21], "clean": 10, "cleanrl": [10, 25], "cleanup": 16, "cli": 11, "clip": [3, 9, 10], "clip_coef": 10, "clip_grad_norm_": 20, "clip_vloss": 10, "close": 6, "closest": 19, "cn": 3, "cnn": 20, "code": [2, 9, 10, 16, 21, 25], "coeffici": [2, 3, 4, 10, 20], "collect": [8, 10, 20], "com": [2, 9, 10, 16, 21], "commit": 25, "common": [11, 14, 16, 17, 19, 20, 21, 22, 23, 24, 26], "compar": [3, 6, 22], "complet": 19, "complex": 22, "compon": 23, "comput": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 16, 17, 19, 20, 21, 22], "compute_corner_weight": 5, "concept": 26, "condit": [0, 2, 3, 13, 17], "conduct": 11, "confer": [9, 10, 11, 25], "config": [3, 6, 7, 10, 13, 14, 18], "configur": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14], "connect": 20, "conor": 15, "consecut": 11, "consid": 22, "constant": 20, "construct": 7, "contain": [0, 6, 13, 16, 17, 18, 19, 25, 26], "continu": [0, 2, 9, 10, 11], "contributor": 15, "control": [10, 11, 20], "converg": 11, "convert": 16, "convex": [2, 11, 21], "convex_hul": 21, "copi": 16, "core": 6, "corner": 5, "correct": 11, "correspond": [16, 20], "count": 18, "coverag": [11, 21], "cpu": 13, "creat": [3, 14, 20], "credit": 9, "criteria": 25, "critic": [2, 10], "crowd": 16, "crowding_divers": 16, "csail": 10, "cuda": 13, "current": [0, 3, 5, 8, 10, 11, 15, 16, 17, 19, 20, 22], "current_estim": 22, "current_front": 17, "current_iter": 10, "current_weight": 19, "customli": 22, "d": [0, 10, 11, 13, 18, 22], "da": [4, 25], "daniel": 2, "danoi": [18, 25], "dashboard": 25, "data": [10, 16], "ddqn_target": 3, "decai": [3, 4, 7, 8, 14, 19], "decay_period": 19, "decompos": 6, "decomposit": [6, 25], "deep": 20, "default": [2, 5, 8, 9, 10, 11, 16, 17, 18, 21, 22, 24], "definit": [5, 25], "delet": 7, "delete_indx": 7, "delete_polici": 7, "delta": 10, "delta_weight": 10, "deni": 15, "design": [7, 14, 25], "desir": 9, "desired_horizon": 9, "desired_return": 9, "detail": [6, 10, 25, 26], "determin": [6, 10, 16], "determinist": 0, "deviat": 9, "devic": [2, 3, 4, 6, 9, 10, 13, 16], "dict": [3, 6, 7, 8, 9, 10, 13, 14, 17], "dictionari": [3, 6, 7, 8, 10, 13, 14, 16, 17], "diederik": 4, "differ": [10, 15, 18, 25], "dim": 24, "dimens": [9, 16, 20, 23], "directli": 15, "directori": [3, 18, 19], "dirichlet": 24, "discord": 15, "discount": [2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 17], "discret": [0, 15], "discuss": [15, 18], "dist": 24, "dist_metr": [6, 19], "distanc": [6, 11, 16, 17, 19, 22], "distribut": [18, 24], "diverg": 10, "divers": 11, "diverse_buff": 16, "diversememori": 16, "do": 11, "document": [11, 25, 26], "doi": [7, 11, 14, 18], "domin": [5, 8, 21, 23], "done": [3, 16], "dot": [17, 22, 23], "doubl": 3, "dqn": [3, 19, 20], "drop_rat": [4, 20], "dropout": [4, 20], "drugan": [7, 14], "dtype": 22, "dupe": 16, "duplic": 21, "dure": [2, 8, 10], "dyna": [7, 14], "dyna_upd": [7, 14], "dynam": 4, "dynamics_buffer_s": 4, "dynamics_ensemble_s": 4, "dynamics_net_arch": 4, "dynamics_normalize_input": 4, "dynamics_num_elit": 4, "dynamics_rollout_batch_s": 4, "dynamics_rollout_freq": 4, "dynamics_rollout_len": 4, "dynamics_rollout_start": 4, "dynamics_train_freq": 4, "dynamics_uncertainty_threshold": 4, "dynmorl": 16, "e": [2, 3, 4, 6, 7, 8, 9, 10, 13, 16, 17, 18, 22, 25], "each": [4, 6, 10, 11, 14, 16, 18, 20, 22, 23], "earli": 18, "easili": 6, "edu": 10, "effect": 17, "effici": [4, 6], "either": [5, 24], "el": 25, "element": [16, 19, 21, 24], "elit": 4, "els": 10, "emb": 3, "end": [4, 5, 16], "energi": 24, "enforc": [16, 25], "enhanc": 10, "ensembl": 4, "ensur": 11, "ent_coef": 10, "entiti": [2, 3, 4, 7, 8, 9, 10, 13, 14], "entropi": [2, 10], "env": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 19], "env_id": 10, "envelop": [0, 18], "envelope_target": 3, "environ": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 19, 25, 26], "episod": [2, 3, 4, 6, 7, 8, 9, 13, 17, 19], "epoch": 10, "epsilon": [3, 4, 5, 7, 8, 14, 16, 19], "epsilon_decay_step": [3, 4, 7, 8, 14], "epsilon_ol": 7, "equal": [11, 24], "equally_spaced_weight": 24, "equival": 24, "error": 16, "esr": [0, 6, 13, 16, 17, 25, 26], "essenti": 10, "estim": 10, "et": [11, 19, 20], "etc": [25, 26], "eum": [11, 17, 22], "eupg": [0, 6, 15], "eval": [2, 3, 4, 7, 9, 10, 11, 13, 14], "eval_after_pg": 10, "eval_before_pg": 10, "eval_env": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "eval_freq": [2, 3, 4, 7, 13, 14, 18], "eval_mo": 17, "eval_mo_freq": 4, "eval_mo_reward_condit": 17, "eval_ref_point": 8, "evalu": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 21], "evaluation_mod": 6, "everi": [3, 8, 13], "evolutionari": 10, "evolutionary_iter": 10, "ex": 5, "exampl": [18, 25, 26], "exchang": 6, "exchange_everi": 6, "expect": [0, 2, 3, 4, 6, 7, 8, 9, 11, 13, 17, 22], "expected_util": 22, "experi": [2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 18, 25], "experiment": 25, "experiment_nam": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "explor": 3, "extend": 2, "extract": [16, 20], "extract_trac": 16, "extrema": 24, "extrema_weight": 24, "f": [11, 15, 18, 22], "f_scale": 10, "factor": [2, 3, 4, 7, 8, 9, 10, 13, 14], "fals": [2, 3, 4, 5, 6, 7, 10, 14, 16, 17, 18, 20, 21], "far": [19, 23], "fast": 21, "featur": [0, 15, 20], "features_dim": 20, "felten": [15, 18, 25], "felten_toolkit_2023": 25, "few": 10, "ffelten": 15, "file": [2, 6, 18, 26], "filenam": [2, 3, 4, 6, 9], "fill": [9, 16, 17], "filter_convex_domin": 21, "filter_pareto_domin": 21, "final": [3, 4, 7, 8, 11, 14, 19], "final_epsilon": [3, 4, 7, 8, 14], "final_homotopy_lambda": 3, "final_valu": 19, "find": 16, "first": [4, 21], "fix": 15, "float": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 22, 23], "float32": 16, "florian": [15, 25], "flow": 11, "follow": [0, 7, 11, 16, 18, 19, 20, 25, 26], "form": 21, "format": [11, 25], "forward": 20, "found": [11, 25], "fp": 19, "framework": [6, 25], "free": 16, "frequenc": [3, 4, 7, 13], "from": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 22, 24, 25], "front": [2, 3, 4, 6, 7, 8, 9, 11, 17, 21, 22], "full": [11, 16, 22], "fulli": 20, "fullpath": 19, "function": [4, 5, 6, 7, 8, 10, 11, 13, 14, 16, 17, 20, 21, 22, 25], "further": 10, "futur": 13, "g": [2, 3, 4, 6, 7, 8, 9, 10, 13, 18, 22, 25], "gae": 10, "gae_lambda": 10, "gain": 20, "gamma": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "gareev": 18, "gather": 10, "gaussian": 24, "gener": [3, 4, 5, 6, 7, 11, 13, 14, 17, 19, 22, 24], "get": [2, 5, 7, 8, 9, 15, 16], "get_all_data": 16, "get_buff": 13, "get_config": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "get_corner_weight": 5, "get_data": 16, "get_error": 16, "get_grad_norm": 20, "get_local_pc": 8, "get_non_domin": 21, "get_non_dominated_ind": 21, "get_non_pareto_dominated_ind": 21, "get_policy_net": 13, "get_q_set": 8, "get_save_dict": 13, "get_sec_writ": 16, "get_trace_valu": 16, "get_weight_support": 5, "ghazali": 25, "gif": 19, "github": [2, 9, 10, 16], "give": [3, 13, 14, 16], "given": [2, 3, 4, 7, 8, 9, 10, 13, 14, 16, 20], "global": 17, "global_step": 17, "global_timestep": 17, "goir": 25, "good": [11, 22], "gpi": [0, 2, 5, 7, 14], "gpi_act": 4, "gpi_ag": 5, "gpi_expanded_set": 5, "gpi_ls_prior": 5, "gpi_pd": [4, 7, 14], "gpipd": 4, "gr": 25, "grad": 20, "gradient": [0, 2, 3, 4, 10, 13], "gradient_upd": [2, 3, 4], "greedi": [3, 4, 14], "greedili": 3, "group": [3, 10], "guid": [10, 11, 25], "gym": [2, 4, 8, 9], "gymnasium": [6, 11, 17, 25, 26], "ha": [10, 17, 18], "haoy": 2, "haoyelu": 2, "happi": 15, "have": [0, 10, 11, 15, 19, 21, 25], "hay": [11, 15], "help": 15, "henc": 11, "here": [11, 15, 25], "herman": 2, "hi": 15, "hidden": [3, 9], "hidden_dim": 9, "highest": [3, 5], "histor": 10, "homotopi": 3, "homotopy_decay_step": 3, "hook": 25, "horizon": 9, "how": 20, "hp": 18, "html": [10, 11, 24], "http": [2, 3, 4, 5, 9, 10, 11, 16, 21, 24, 25], "huber": 20, "hull": 21, "human": 20, "hv": 22, "hv_ref_point": 17, "hybrid": 11, "hyperparam": 18, "hyperparamet": 25, "hyperparameter_search": 18, "hypervolum": [2, 3, 4, 6, 7, 8, 9, 11, 17, 18, 22], "i": [3, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26], "iclr": 2, "id": [2, 10, 13, 14, 16, 17, 18, 19], "idea": [6, 11, 13, 15], "identifi": [16, 22], "idx": 16, "ifaama": 9, "igd": [11, 17, 22], "ignor": 3, "implement": [0, 5, 6, 10, 11, 15, 16, 25, 26], "import": 21, "improv": [4, 5, 6, 7, 14, 15], "includ": 16, "include_indic": 16, "include_w": 4, "index": 16, "indic": [5, 7, 16, 21], "ineffici": 21, "info": [3, 5, 17], "inform": [13, 17, 25], "initi": [3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 20, 21], "initial_epsilon": [3, 4, 7, 8, 14], "initial_homotopy_lambda": 3, "initial_valu": 19, "inproceed": 25, "input": [3, 4, 20, 21], "input_dim": 20, "insid": 20, "int": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 22, 23, 24], "integ": 3, "integr": 16, "intern": [9, 10, 11], "introduc": 18, "invert": [17, 22], "is_domin": 5, "issu": [11, 15, 25], "iter": [2, 4, 5, 7, 10, 20], "its": [8, 16, 21, 22], "j": [10, 11], "jayden": 15, "jiex": 10, "join": 15, "journal": 8, "just": 6, "k": [3, 7, 8, 14], "kanter": [11, 22], "keep": [3, 10], "kept": 21, "keyword": 11, "kl": 10, "know": [11, 16, 22], "known": [2, 3, 4, 6, 7, 8, 9, 17, 22], "known_front": 22, "known_pareto_front": [2, 3, 4, 6, 7, 8, 9, 10], "l": [0, 4, 5, 7, 11, 22, 25], "lambda": [4, 6, 10, 16], "last": [17, 20], "launch": [14, 18], "launch_experi": [11, 18], "launch_sweep": 18, "layer": [3, 4, 10, 13, 20], "layer_init": 20, "layer_norm": [4, 20], "lean": [3, 18], "learn": [0, 4, 6, 9, 10, 11, 13, 15, 16, 18, 20, 22], "learning_r": [2, 3, 4, 7, 9, 10, 13, 14], "learning_start": [2, 3, 4, 14], "length": [4, 19, 20], "level": [16, 20], "leverag": 21, "librari": [16, 25], "life": 11, "like": 15, "limit": 0, "linear": [0, 7, 13], "linear_support": 5, "linearli": 19, "linearly_decaying_valu": 19, "linearreward": 17, "linearsupport": 5, "lint": 25, "list": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 16, 17, 19, 20, 21, 22, 24], "literatur": 11, "load": [2, 3, 4, 6, 9, 13], "load_replay_buff": [2, 3, 4, 6, 13], "local": 8, "locat": 11, "log": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 17], "log_all_multi_policy_metr": 17, "log_episode_info": 17, "log_everi": [8, 13], "long": 11, "longer": 5, "look": 10, "loop": [0, 7], "loss": [10, 11, 17, 20, 22], "low": 16, "lu": 2, "luca": [4, 15, 25], "lucasalegr": 15, "m": [4, 7, 9, 11, 14, 22], "ma": [10, 11], "machin": [8, 10, 11], "made": [21, 22], "mai": 9, "main": [3, 10, 15, 16, 17], "main_capac": 16, "main_mem_is_ful": 16, "maintain": 14, "mainten": 11, "make": [10, 17], "make_gif": 19, "mani": 15, "manner": 25, "master": 10, "materi": [0, 10], "mathieu": [9, 15], "matusik": [10, 11], "max": 14, "max_act": [3, 4], "max_buffer_s": 9, "max_grad_norm": [3, 4, 10], "max_iter": 10, "max_return": 9, "max_sampl": 16, "max_scalar_q_valu": 7, "max_scalarized_valu": 5, "max_siz": 16, "max_value_lp": 5, "max_weight": 10, "maximum": [3, 4, 5, 7, 9, 10, 11, 16, 17, 22], "maximum_utility_loss": 22, "mdp": 25, "mechan": 6, "memori": [16, 21], "merg": 11, "method": [3, 5, 6, 7, 8, 11, 14, 16, 20, 24], "metric": [6, 7, 8, 9, 17, 19, 22], "might": 10, "min_prior": [4, 14, 16, 20], "min_weight": 10, "minecart": 18, "minibatch": 10, "minimum": [4, 5, 10, 14, 16, 20], "misc": 24, "mislead": 22, "mit": 10, "mlp": 20, "mlr": [10, 11], "mnih": [19, 20], "mo": [0, 7, 11, 14, 17, 25, 26], "mo_ppo": 10, "mo_q_learn": [7, 14], "model": [3, 4, 9, 14], "model_bas": 14, "model_class": 9, "modifi": 10, "modul": [13, 20], "moffaert": [7, 8, 14], "momdp": 25, "moo": [11, 22], "mopolici": 5, "mopponet": 10, "moq": 7, "moql": 0, "moqlearn": 14, "more": [5, 6, 10, 26], "moreov": 11, "morl": [0, 2, 3, 4, 7, 8, 9, 10, 11, 13, 14, 15, 18, 19, 22, 26], "morl_baselin": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 19, 20, 21, 22, 23, 24], "morld": 6, "mosac": [6, 15], "mostli": 22, "move": [14, 16], "move_to_sec": 16, "mp_mo_q_learn": 7, "mpmoqlearn": [0, 7, 14], "much": 26, "mul": [11, 17, 22], "multi": [0, 2, 3, 4, 6, 7, 8, 10, 13, 14, 17, 18, 20, 22, 26], "multi_polici": [2, 3, 4, 5, 6, 7, 8, 9, 10, 26], "multi_policy_moqlearn": 7, "multiag": 9, "multipl": [0, 3, 6, 10, 16, 17, 19], "multipolici": 7, "must": 5, "n": [4, 9, 13, 15, 16, 19, 24, 25], "n_sample_weight": 17, "name": [0, 2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 18], "narasimhan": 3, "natur": [19, 20], "naturecnn": 20, "ndarrai": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 17, 19, 20, 21, 22, 23, 24], "nearest": [19, 22], "nearest_neighbor": 19, "need": [13, 22], "neighbor": 19, "neighbordhood": 6, "neighborhood": [6, 10], "neighborhood_s": 6, "neighborhood_threshold": 10, "net": [2, 3, 10, 13, 20, 26], "net_arch": [2, 3, 4, 10, 13, 20], "network": [0, 2, 3, 4, 10, 13], "neural": [25, 26], "neurip": 25, "new": [5, 7, 10, 13, 14, 15, 16], "new_valu": 5, "new_weight": 10, "next": [5, 10, 16], "next_ob": 16, "next_weight": 5, "nn": [13, 20], "node": 16, "nois": 9, "non": [8, 13, 21], "none": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 17, 20, 24], "norm": [3, 4, 10, 20], "norm_adv": 10, "normal": [4, 10, 16, 20, 24], "note": 10, "nov": [3, 10, 11], "novel": [7, 14], "now": [6, 7, 13, 14, 25], "now\u00e9": [4, 8, 9], "np": [2, 3, 4, 5, 9, 13, 14, 17, 19, 22], "num": 18, "num_env": 10, "num_er_episod": 9, "num_eval_episodes_for_front": [2, 3, 4, 6, 7], "num_eval_weights_for_ev": [2, 3, 4, 6, 7, 8, 9, 10], "num_eval_weights_for_front": [2, 3, 4, 7, 18], "num_minibatch": 10, "num_model_upd": 9, "num_net": 4, "num_object": 5, "num_performance_buff": 10, "num_points_pf": 9, "num_q_net": 2, "num_sample_w": 3, "num_step_episod": 9, "num_weight_candid": 10, "number": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 24], "numpi": [6, 10, 14, 16, 17, 21, 22, 23, 25], "ob": [2, 3, 4, 5, 7, 9, 10, 13, 14, 16], "object": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 22], "obs_dtyp": 16, "obs_shap": 16, "observ": [0, 2, 3, 9, 10, 13, 14, 16, 20], "observation_shap": 20, "oct": 18, "offici": 11, "ol": [0, 5, 7], "oliehoek": [11, 22], "ols_prior": 5, "onc": 17, "one": [4, 6, 14, 17, 22, 24], "onli": [6, 17, 22, 25], "onlin": 3, "open": [15, 25], "openreview": 2, "openrlbenchmark": [11, 25], "optim": [2, 3, 4, 5, 6, 7, 8, 9, 11, 22, 25], "optimist": [0, 5, 7], "option": [2, 3, 4, 5, 7, 8, 9, 13, 14, 17, 21], "org": [3, 4, 5, 9, 24], "origin": [10, 11, 15], "orthogon": 20, "other": [11, 14, 16, 25], "otherwis": [5, 7, 19], "our": [10, 11, 15, 25], "outer": [0, 7], "output": 20, "output_dim": 20, "over": [3, 7, 14, 19], "overview": 25, "p": [10, 11, 22], "p1110": 9, "pair": [8, 16], "paper": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 18, 20, 22, 25], "parallel": 19, "param": 20, "paramet": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24], "parent": [13, 14], "parent_rng": [13, 14], "pareto": [0, 3, 4, 6, 7, 10, 11, 15, 17, 22, 25], "pareto_q_learn": 8, "paretoarch": 21, "part": 10, "particip": 25, "pass": 13, "past": 16, "path": [2, 3, 4, 6, 9, 13], "pc": 8, "pcn": [0, 9, 15], "pcn_model": 9, "pd": [0, 2, 4, 7, 14], "pdf": [2, 5, 9, 10], "peopl": [10, 15], "per": [2, 3, 4, 5, 7, 8, 9, 10, 13, 14, 17, 20], "per_alpha": 3, "perceptron": 20, "perform": [7, 10, 14, 25], "performance_buffer_s": 10, "performance_ind": [11, 22], "performancepredictor": 10, "period": 19, "pf": [11, 22], "pgmorl": [0, 11, 22], "phase": 10, "plan": [11, 25], "pleas": 25, "plot": 11, "point": [2, 3, 4, 6, 7, 8, 9, 10, 11, 17, 18, 21, 22, 23], "pointer": 13, "polici": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 17, 22, 25, 26], "policy_arg": 6, "policy_ev": 10, "policy_evaluation_mo": 17, "policy_nam": 6, "polyak": 20, "polyak_upd": 20, "pop_siz": [6, 10], "popul": [6, 10], "popular": 25, "posit": [10, 16], "possibl": [10, 11, 19, 26], "post": 10, "posteriori": 11, "potenti": [6, 13], "power": 16, "pp": [8, 9, 10, 11], "ppo": 10, "ppo_continuous_act": 10, "pql": 8, "practic": [11, 25], "pre": 25, "pred_idx": 16, "predict": [11, 20], "predict_next_evalu": 10, "predictor": 10, "prefer": 17, "present": 11, "press": [10, 11], "previou": [5, 7, 16], "print": [3, 5, 17], "priorit": [3, 7, 14], "prioriti": [4, 5, 14, 16, 20], "prioritized_buff": 16, "prioritizedreplaybuff": 16, "problem": [6, 11, 18, 22], "proceed": [9, 10, 11, 25], "process": [10, 17, 25], "product": [22, 23], "progress": 11, "project": [2, 3, 4, 7, 8, 9, 10, 13, 14, 15], "project_nam": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "proport": 16, "propos": 11, "protocol": 25, "provid": [10, 15, 16, 17, 21, 25], "prune": [8, 21, 25], "psa": 6, "pub": 5, "pull": 15, "purpos": 11, "py": [10, 11, 18], "pymoo": [22, 24], "python": [17, 18, 21], "pytorch": [16, 25], "q": [0, 7, 14, 15, 18], "qualiti": [11, 22], "queri": 11, "question": [15, 21], "queue": 5, "quickhul": 21, "r": [3, 22], "rais": 16, "random": [3, 4, 6, 7, 8, 10, 13, 14, 17, 24], "random_weight": 24, "randomli": 3, "rate": [2, 3, 4, 7, 9, 10, 13, 14, 20], "ratio": 4, "read": 25, "real": 4, "real_ratio": 4, "recal": 14, "receiv": 15, "recommend": 22, "recordstatisticswrapp": 17, "recur": 26, "recurs": 16, "reduc": 16, "ref": [8, 18], "ref_front": 17, "ref_point": [2, 3, 4, 6, 7, 8, 9, 10, 22], "refactor": [9, 10], "refer": [2, 3, 4, 6, 7, 8, 9, 10, 17, 18, 22, 23], "reference_direct": 24, "reference_set": 22, "regress": 10, "regular": 2, "reinforc": [0, 2, 3, 6, 7, 8, 10, 11, 13, 14, 16, 18, 20], "relat": [17, 24], "relev": 16, "reli": [8, 10, 11, 14, 22, 23], "reliabl": 25, "relu": 20, "remov": [5, 16, 21], "remove_dupl": 21, "remove_obsolete_valu": 5, "remove_obsolete_weight": 5, "remove_trac": 16, "render": [17, 19], "rep": 17, "rep_ev": 5, "replac": 16, "replai": [2, 3, 4, 6, 9, 13, 26], "replaybuff": 16, "repo": 26, "report": 25, "repositori": [15, 25], "repres": [3, 20], "reproduc": [7, 9, 11, 13, 17, 25], "request": 15, "requir": [11, 22, 23], "research": [8, 25], "reserved_idx": 16, "reset": [2, 3, 4, 6, 14, 19], "reset_learning_start": [3, 4], "reset_num_timestep": [2, 3, 4, 6, 14, 18], "reset_wandb_env": 19, "respect": 11, "rest": 24, "result": [8, 10, 11, 25], "retriev": 13, "return": [3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 19, 20, 21, 22, 23, 25], "return_policy_index": 4, "reus": 7, "rew_dim": 16, "reward": [13, 17, 23, 25], "reward_dim": [17, 23], "reymond": [9, 15], "riesz": 24, "rl": [2, 6, 10, 22, 25], "rng": [6, 10, 24], "robot": [10, 11], "roijer": [4, 5, 11, 13, 22], "rollout": 4, "ru": [10, 11], "rule": 26, "run": [2, 3, 4, 7, 10, 11, 13, 17, 19, 25], "r\u00f6pke": 15, "s10458": 11, "sake": 11, "same": [8, 16, 18, 19], "sampl": [3, 4, 6, 9, 10, 16, 17, 24], "sample_ob": 16, "sampled_w": 3, "save": [2, 3, 4, 6, 9, 13, 19], "save_dict": 13, "save_dir": [2, 3, 4, 6, 9], "save_freq": [2, 6], "save_replay_buff": [2, 3, 4, 6, 13], "scalar": [3, 5, 6, 7, 10, 11, 13, 14, 17], "scalarization_method": 6, "scalarized_discounted_return": 11, "scalarized_q_valu": 14, "scalarized_return": 11, "scale": [9, 10], "scaling_factor": 9, "schedul": 19, "score": 8, "score_func": 8, "score_hypervolum": 8, "score_pareto_cardin": 8, "script": [17, 18], "search": 18, "sec_capac": 16, "sec_dist": 16, "secondari": 16, "secondary_trac": 16, "section": [0, 5, 10], "see": [5, 6, 10, 26], "seed": [2, 3, 4, 6, 7, 8, 9, 10, 11, 13, 14, 17, 18, 24], "seed_everyth": 17, "seen": 23, "select": [3, 4, 7, 8, 10], "select_act": 8, "self": 10, "sent": 11, "sep": 3, "sequenti": [6, 20], "ser": [0, 6, 10, 14, 25, 26], "server": 15, "set": [3, 4, 5, 6, 7, 8, 9, 11, 13, 16, 17, 18, 21, 22, 25, 26], "set_buff": 13, "set_desired_return_and_horizon": 9, "set_weight": 13, "set_weight_support": 4, "sever": 15, "shape": [16, 20], "share": [6, 13], "shared_buff": 6, "sharing_mechan": 6, "should": [5, 6, 10, 16, 17, 21], "sigma": 10, "sign": 5, "silva": [4, 25], "similar": [19, 22], "simplex": [11, 24], "singl": [0, 6, 14, 25, 26], "single_polici": [10, 13, 14, 26], "size": [2, 3, 4, 6, 9, 10, 13, 16, 24], "small": 20, "smooth": 14, "so": [17, 18, 19, 23], "soft": [2, 3, 4], "solut": [18, 21], "solv": 6, "some": [0, 10, 11, 22, 25], "someth": [6, 10], "sota": 11, "sourc": [16, 21], "sp": 13, "space": [0, 10, 11, 22, 24], "span": 16, "sparsiti": [10, 11, 22], "sparsity_coef": 10, "specifi": [3, 16, 18], "spot": 16, "src_i": 16, "stabl": 25, "stackoverflow": 21, "stage": 10, "standard": [9, 25], "start": [2, 3, 4, 10, 13, 14, 16, 18], "start_tim": [10, 13, 14], "state": [7, 8, 17, 22], "stationar": 2, "statist": 17, "steckelmach": [13, 15], "step": [2, 3, 4, 7, 8, 9, 10, 14, 17, 19], "steps_per_iter": 10, "store": [10, 16], "str": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 19, 22, 24], "strictli": 25, "structur": 26, "subset": 21, "sueda": [10, 11], "suffici": 16, "suggest": 25, "sum": [10, 23], "sun": 3, "supp": 10, "supplementari": [0, 10], "support": [0, 4, 6, 7, 10, 11, 25], "sure": 23, "sweep": [18, 19], "syncvectorenv": 10, "system": [9, 11, 25], "t": [11, 22], "tabl": [0, 7, 11, 14], "tabular": 8, "tabular_model": 14, "tabularmodel": 14, "take": [2, 3, 17], "taken": 19, "talbi": [18, 25], "target": [3, 4, 10, 16, 20], "target_kl": 10, "target_net_update_freq": [3, 4], "target_param": 20, "tau": [2, 3, 4, 20, 23], "taxonomi": 25, "tch": 6, "tchebicheff": 23, "techniqu": [6, 7, 14, 25], "tensor": [2, 3, 4, 16, 20], "teoh": 15, "term": [10, 11], "test": [5, 11, 25], "th": [2, 9], "than": [5, 10], "thank": 15, "them": [11, 15], "therefor": 22, "thesi": [0, 5], "thi": [3, 5, 6, 9, 10, 11, 15, 16, 17, 19, 20, 21, 22, 23, 25, 26], "those": 16, "threshold": [4, 10], "through": 20, "tian": [10, 11], "time": [3, 5, 6, 9, 10, 13, 14], "timestep": [2, 3, 4, 6, 7, 8, 13, 14, 17], "timesteps_per_it": 4, "timesteps_per_iter": 7, "titl": 25, "tjezisyesq6": 2, "to_tensor": 16, "tol": [8, 19], "toler": [8, 19], "too": 3, "toolkit": 25, "top_k": 5, "torch": [4, 6, 20], "torch_act": 2, "total": [2, 3, 6, 7, 9], "total_episod": 3, "total_timestep": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 18], "trace": 16, "trace_divers": 16, "trace_id": 16, "trace_tupl": 16, "track": [8, 11, 25], "track_polici": 8, "tradeoff": 10, "train": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 17, 18, 19], "train_iter": 4, "transfer": 6, "transfer_q_t": 7, "transit": [0, 4, 16], "treat": 16, "tree": 16, "tree_id": 16, "trg_i": 16, "tri": 26, "trick": 6, "trigger": 6, "true": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 21, 22], "try": [18, 19], "tupl": [10, 16, 17], "tutori": 25, "type": [4, 6, 9, 16, 20, 22], "typo": 5, "u": 15, "uncertainti": 4, "under": 25, "underli": 6, "uniform": 6, "uniformli": 24, "union": [2, 9], "uniqu": 19, "unique_tol": 19, "unit": [10, 13, 20], "until": [3, 19], "updat": [2, 3, 4, 6, 7, 9, 10, 13, 14, 16, 20], "update_epoch": 10, "update_pass": 6, "update_prior": 16, "upon": 8, "upper": 5, "us": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 16, 17, 18, 19, 20, 22, 24, 25, 26], "usag": 18, "use_c": 16, "use_gpi": [4, 7], "use_gpi_polici": [7, 14], "user": 11, "usual": [10, 20], "util": [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 17, 19, 20, 22, 24, 25], "v": [11, 22], "v0": 18, "v119": [10, 11], "valu": [3, 4, 5, 7, 8, 10, 11, 14, 16, 17, 18, 19, 22, 23], "value_funct": 16, "van": [7, 8, 14], "variabl": 19, "variou": [10, 11, 15, 22, 25], "vec": 8, "vector": [2, 3, 4, 5, 6, 8, 10, 17, 19, 20, 21, 22, 23, 24], "vectorizedenv": 10, "verbos": [3, 5, 17], "version": [7, 21], "vf_coef": 10, "via": 4, "vol": [8, 11], "volodymyr": 20, "vwxyzjn": 10, "w": [2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 17], "w_new": 5, "wa": 16, "wai": [15, 16], "wait": 14, "wandb": [2, 3, 4, 6, 8, 9, 10, 11, 13, 19, 25], "wandb_ent": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14], "want": [11, 15, 19], "warmup": 10, "warmup_iter": 10, "warmup_step": 19, "warn": [0, 5, 11], "we": [11, 15, 16, 19, 22, 25], "websit": 25, "weight": [2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 17, 19, 20, 22, 23, 25], "weight_adaptation_method": 6, "weight_candid": 10, "weight_gain": 20, "weight_init_method": 6, "weight_list": 4, "weight_selection_algo": [4, 7], "weight_support": 4, "weighted_sum": [7, 14, 23], "weights_set": 22, "well": [19, 25], "were": 11, "when": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 19, 22], "where": [15, 19], "wherea": 11, "whether": [2, 3, 4, 6, 7, 8, 9, 10, 13, 14, 16, 17, 20, 21], "which": [3, 5, 6, 10, 11, 16, 19, 20, 21, 25], "who": 15, "whole": 16, "whose": [10, 16], "willem": 15, "wilrop": 15, "within": 19, "without": 16, "work": 11, "would": 15, "wrapper": 17, "write": 16, "wrong": 21, "www": 9, "x": [3, 20], "xu": [10, 11], "xu20h": [10, 11], "y": [10, 11], "yaml": 18, "yang": 3, "yaoliang": 2, "year": 25, "yet": 10, "you": [15, 25], "your": [15, 25], "yu": 2, "zintgraf": [11, 22]}, "titles": ["Overview", "Multi-Policy Algorithms", "Concave-Augmented Pareto Q-Learning (CAPQL)", "Envelope Q-Learning", "GPI-Prioritized Dyna", "Linear Support", "MORL/D", "MPMOQ Learning", "Pareto Q-Learning", "Pareto Conditioned Networks", "PGMORL", "Performance assessments", "Single-policy Algorithms", "EUPG", "MOQ-Learning", "Community", "Replay Buffers", "Evaluations", "Hyperparameter optimization", "Miscellaneous", "Neural Networks helpers", "Pareto utils", "Performance indicators", "Scalarization functions", "Weights helpers", "MORL-Baselines: A collection of multi-objective reinforcement learning algorithms.", "Overview"], "titleterms": {"A": 25, "accru": 16, "acknowledg": 15, "algorithm": [1, 11, 12, 25], "applic": 10, "assess": 11, "augment": 2, "baselin": 25, "benchmark": [11, 25], "buffer": 16, "capql": 2, "cite": 25, "collect": 25, "commun": 15, "concav": 2, "condit": 9, "contribut": 15, "d": 6, "divers": 16, "dyna": 4, "envelop": 3, "eupg": 13, "evalu": 17, "featur": 25, "function": 23, "gener": 10, "gpi": 4, "helper": [20, 24], "hyperparamet": 18, "indic": 22, "introduct": 11, "learn": [2, 3, 7, 8, 14, 25], "limit": 10, "linear": 5, "maintain": 15, "metric": 11, "miscellan": 19, "model": 10, "moppo": 10, "moq": 14, "morl": [6, 25], "mpmoq": 7, "multi": [1, 11, 16, 25], "network": [9, 20], "neural": 20, "object": [16, 25], "optim": 18, "overview": [0, 26], "pareto": [2, 8, 9, 21], "perform": [11, 22], "pgmorl": 10, "polici": [1, 11, 12], "predict": 10, "principl": 10, "priorit": [4, 16], "q": [2, 3, 8], "refer": 11, "reinforc": 25, "replai": 16, "reward": 16, "scalar": 23, "script": 11, "singl": [11, 12], "storag": 11, "support": 5, "util": 21, "weight": [10, 24]}})